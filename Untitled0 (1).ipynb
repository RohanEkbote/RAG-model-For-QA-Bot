{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOijbfOnupCz",
        "outputId": "7167c23a-2a40-40ed-aa5f-e4799b41521e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.9.0 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4FmAs6auzIE",
        "outputId": "e0afd8ba-133b-4aad-d55f-1e218072eb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-3.0.1-py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.0/201.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2023.11.17)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Installing collected packages: pinecone-client\n",
            "Successfully installed pinecone-client-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pinecone\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cbXyx6cnvBVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
        "pinecone.init(api_key='YOUR_PINECONE_API_KEY')"
      ],
      "metadata": {
        "id": "6DLyICB4vHdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create Pinecone index and store document vectors\n",
        "def create_pinecone_index(index_name, data):\n",
        "    pinecone.create_index(index_name, metric=\"cosine\")\n",
        "    pinecone_index = pinecone.Index(index_name)"
      ],
      "metadata": {
        "id": "9ZXRI4AhwMLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Encode text data to vectors using BERT (you may need to install transformers library)\n",
        "    # Example: Use BERT to encode data\n",
        "    # encoded_data = encode_text_data(data)\n",
        "\n",
        "    # Assuming you have vectors ready, insert them into Pinecone index\n",
        "pinecone_index.upsert(items=data)"
      ],
      "metadata": {
        "id": "2KKR05SNxOoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to retrieve relevant documents from Pinecone\n",
        "def retrieve_documents(query, index_name, num_results=5):\n",
        "    pinecone_index = pinecone.Index(index_name)"
      ],
      "metadata": {
        "id": "KJVaEmqtxUKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Encode the query to vector\n",
        "    # query_vector = encode_text_data(query)\n",
        "\n",
        "    # Retrieve relevant documents using Pinecone\n",
        "    response = pinecone_index.query(queries=[query], top_k=num_results)\n",
        "\n",
        "    # Extract document IDs from the response\n",
        "    document_ids = response.results[0].ids\n",
        "\n",
        "    # Fetch the documents from the database\n",
        "    relevant_documents = [data[int(doc_id)] for doc_id in document_ids]\n",
        "\n",
        "    return relevant_documents"
      ],
      "metadata": {
        "id": "Ahr6pBh1xd6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate an answer using OpenAI API\n",
        "def generate_answer(query, documents):\n",
        "    # Combine retrieved documents and query for RAG model\n",
        "    input_text = f\"Query: {query}\\nDocuments:\\n\" + \"\\n\".join(documents)\n",
        "\n",
        "    # Use OpenAI API to generate an answer\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-002\",\n",
        "        prompt=input_text,\n",
        "        max_tokens=100\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].text.strip()\n",
        "\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "gfOn7V9mxh7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "index_name = \"business_qa_index\"\n",
        "data = [\"Document 1 content\", \"Document 2 content\", \"Document 3 content\"]  # Replace with your actual data\n",
        "\n",
        "create_pinecone_index(index_name, data)\n",
        "\n",
        "user_query = \"What is the business about?\"\n",
        "relevant_documents = retrieve_documents(user_query, index_name)\n",
        "answer = generate_answer(user_query, relevant_documents)\n",
        "\n",
        "print(\"User Query:\", user_query)\n",
        "print(\"Relevant Documents:\", relevant_documents)\n",
        "print(\"Generated Answer:\", answer)"
      ],
      "metadata": {
        "id": "0DQkR9Fwxl39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remember to replace placeholder values like 'YOUR_OPENAI_API_KEY' and 'YOUR_PINECONE_API_KEY' with your actual API keys.\n",
        "# Also, you'll need to adapt the code based on your specific data and use case"
      ],
      "metadata": {
        "id": "IBpgsHClxqZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xF6EmWB8x6iM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}